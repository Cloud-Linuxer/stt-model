#!/usr/bin/env python3
"""
STT + LLM í‚¤ì›Œë“œ ì¶”ì¶œ í†µí•© ì„œë²„
"""

import os
import json
import numpy as np
import time
import requests
from pathlib import Path
from flask import Flask, render_template, jsonify
from flask_cors import CORS
from flask_sock import Sock
from faster_whisper import WhisperModel
import base64
import soundfile as sf
import torch
import threading
from queue import Queue
import asyncio

# Flask ì•± ìƒì„±
app = Flask(__name__, template_folder='templates', static_folder='static')
CORS(app, resources={r"/*": {"origins": "*"}})
sock = Sock(app)

# vLLM ì„œë²„ ì„¤ì •
VLLM_API_URL = "http://localhost:8000/v1/completions"

class KeywordExtractor:
    """LLMì„ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ í´ë˜ìŠ¤"""

    def __init__(self):
        self.api_url = VLLM_API_URL
        self.min_importance = 0.8  # ì¤‘ìš”ë„ ì„ê³„ê°’ (ë§¤ìš° ì¤‘ìš”í•œ ëª…ì‚¬ë§Œ)

    def extract_keywords(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text or len(text.strip()) < 10:
            return []

        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ê°œë…ê³¼ ì£¼ì œë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: "{text}"

ì¶”ì¶œ ê·œì¹™:
1. ë°˜ë“œì‹œ ëª…ì‚¬ë§Œ ì¶”ì¶œ (ì‚¬ëŒ, ì¥ì†Œ, íšŒì‚¬, ì œí’ˆ, ê¸°ìˆ , ì¥ë¹„, ì„œë¹„ìŠ¤ ì´ë¦„)
2. ë™ì‚¬ëŠ” ì ˆëŒ€ ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš” (ê°€ë‹¤, ë“£ë‹¤, ìˆë‹¤, í•˜ë‹¤, ë˜ë‹¤, ë¯¸ì¹˜ë‹¤ ë“± ê¸ˆì§€)
3. ë™ì‚¬ì˜ ì–´ê°„ì´ë‚˜ ì–´ë¯¸ë„ ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš” (ë“£ê³ , ê°€ê³ , ìˆëŠ”, ë˜ëŠ” ë“± ê¸ˆì§€)
4. êµ¬ì²´ì ì¸ ëŒ€ìƒì„ ì§€ì¹­í•˜ëŠ” ëª…ì‚¬ë§Œ ì¶”ì¶œ
5. ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ, ê°€ì¥ í•µì‹¬ì ì¸ ëª…ì‚¬ë§Œ

ì ˆëŒ€ ì¶”ì¶œí•˜ë©´ ì•ˆ ë˜ëŠ” ê²ƒë“¤:
- ë™ì‚¬ì™€ ê·¸ í™œìš©í˜•: ë“£ë‹¤, ë“£ê³ , ê°€ë‹¤, ê°€ê³ , ìˆë‹¤, ìˆëŠ”, ë˜ë‹¤, ë˜ëŠ”, í•˜ë‹¤, í•˜ëŠ”, ë¯¸ì¹˜ë‹¤, ë¯¸ì¹˜ëŠ”
- ì¡°ì‚¬: ì€, ëŠ”, ì´, ê°€, ì„, ë¥¼, ì—, ì—ì„œ, ë¡œ, ì™€, ê³¼, ë„, ë§Œ, ê¹Œì§€
- ëŒ€ëª…ì‚¬: ë‚˜, ë„ˆ, ìš°ë¦¬, ê·¸ê²ƒ, ì´ê²ƒ, ì €ê²ƒ
- ê°ì •í‘œí˜„: ã…‹, ã…, ã… 

JSON ì‘ë‹µ:
{{
  "keywords": [
    {{"word": "í‚¤ì›Œë“œ", "importance": 0.9, "category": "ì¹´í…Œê³ ë¦¬"}}
  ]
}}

ì¹´í…Œê³ ë¦¬: ì¸ë¬¼, ì¥ì†Œ, íšŒì‚¬, ê¸°ìˆ , ì œí’ˆ, ì¥ë¹„, ì„œë¹„ìŠ¤, ê¸°íƒ€
ì¤‘ìš”ë„: 0.8 ì´ìƒë§Œ (ë§¤ìš° ì¤‘ìš”í•œ ëª…ì‚¬ë§Œ)

í…ìŠ¤íŠ¸ê°€ ì§§ê±°ë‚˜ ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜.
ì‘ë‹µ:"""

        try:
            response = requests.post(
                self.api_url,
                json={
                    "model": "Qwen/Qwen2.5-7B-Instruct",
                    "prompt": prompt,
                    "max_tokens": 200,
                    "temperature": 0.1,
                    "stop": ["}}", "\n\n"]
                },
                timeout=5
            )

            if response.status_code == 200:
                result = response.json()
                text_response = result['choices'][0]['text']

                # JSON íŒŒì‹±
                try:
                    # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë” ê°•ë ¥í•œ ì²˜ë¦¬)
                    import re

                    # JSON íŒ¨í„´ ì°¾ê¸°
                    json_pattern = r'\{[^{}]*"keywords"[^{}]*\[[^\]]*\][^{}]*\}'
                    json_match = re.search(json_pattern, text_response, re.DOTALL)

                    if json_match:
                        json_text = json_match.group(0)
                    else:
                        # ê¸°ë³¸ ë°©ë²• ì‹œë„
                        if '{' in text_response:
                            json_start = text_response.index('{')
                            # ë§ˆì§€ë§‰ } ì°¾ê¸°
                            json_end = text_response.rfind('}')
                            if json_end > json_start:
                                json_text = text_response[json_start:json_end+1]
                            else:
                                json_text = text_response[json_start:] + '}'
                        else:
                            raise ValueError("No JSON found")

                    data = json.loads(json_text)
                    keywords = data.get('keywords', [])

                    # ì¤‘ìš”ë„ í•„í„°ë§
                    filtered = [k for k in keywords if k.get('importance', 0) >= self.min_importance]

                    # í‚¤ì›Œë“œ ë¡œê¹…
                    if filtered:
                            timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
                            print(f"\n{'='*60}")
                            print(f"ğŸ“ [{timestamp}] ì¶”ì¶œëœ í‚¤ì›Œë“œ:")
                            print(f"   ì›ë³¸ í…ìŠ¤íŠ¸: {text[:100]}...")
                            print(f"   í‚¤ì›Œë“œ ëª©ë¡:")
                            for kw in filtered:
                                print(f"      - {kw['word']} ({kw.get('category', 'ê¸°íƒ€')}, ì¤‘ìš”ë„: {kw['importance']:.1f})")
                            print(f"{'='*60}\n")

                            # íŒŒì¼ë¡œë„ ë¡œê¹…
                            with open("/tmp/keywords_log.txt", "a", encoding="utf-8") as f:
                                f.write(f"\n[{timestamp}]\n")
                                f.write(f"í…ìŠ¤íŠ¸: {text}\n")
                                f.write(f"í‚¤ì›Œë“œ: {', '.join([k['word'] for k in filtered])}\n")
                                f.write("-" * 50 + "\n")

                    return filtered
                except json.JSONDecodeError:
                    print(f"JSON íŒŒì‹± ì‹¤íŒ¨: {text_response}")
                    return self._fallback_extraction(text)

        except Exception as e:
            print(f"LLM í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return self._fallback_extraction(text)

        return []

    def _fallback_extraction(self, text):
        """LLM ì‹¤íŒ¨ì‹œ ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re

        # ì¡°ì‚¬, ì–´ë¯¸ ì œê±° íŒ¨í„´
        text_clean = re.sub(r'[ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œë„ì˜ë¡œë¶€í„°ê¹Œì§€ë§Œ]+\s', ' ', text)
        text_clean = re.sub(r'[ìŠµë‹ˆë‹¤ë‹ˆê¹Œì„¸ìš”ì–´ìš”ì•„ìš”ì£ ë„¤ìš”]+[\s\.\,\!]', ' ', text_clean)

        # ë‹¨ì–´ ì¶”ì¶œ
        words = text_clean.split()
        keywords = []
        seen = set()

        for word in words:
            # íŠ¹ìˆ˜ë¬¸ì ì œê±°
            word = re.sub(r'[^\wê°€-í£a-zA-Z0-9]', '', word)

            # 2ê¸€ì ì´ìƒ, ì¤‘ë³µ ì œê±°
            if len(word) >= 2 and word not in seen:
                seen.add(word)
                keywords.append({
                    "word": word,
                    "importance": 0.6,
                    "category": "ê¸°íƒ€"
                })

        return keywords[:5]  # ìƒìœ„ 5ê°œë§Œ

class WhisperProcessor:
    """Whisper STT ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.model = None
        self.device = "cuda"
        self.sample_rate = 16000
        self.processing_queue = Queue()
        self.worker_thread = None
        self.keyword_extractor = KeywordExtractor()
        # Hallucination í•„í„°ë§ì„ ìœ„í•œ íŒ¨í„´
        self.hallucination_patterns = [
            "ì‹œì²­í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
            "ì‹œì²­í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
            "MBC ë‰´ìŠ¤",
            "KBS ë‰´ìŠ¤",
            "SBS ë‰´ìŠ¤",
            "YTN ë‰´ìŠ¤",
            "ì…ë‹ˆë‹¤",
            "ê°ì‚¬í•©ë‹ˆë‹¤",
            "êµ¬ë…ê³¼ ì¢‹ì•„ìš”",
            "ì•Œë¦¼ ì„¤ì •"
        ]
        self.recent_texts = []  # ìµœê·¼ ì¸ì‹ í…ìŠ¤íŠ¸ ì €ì¥

    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘ (GPU ëª¨ë“œ)...")

        if torch.cuda.is_available():
            print(f"âœ… GPU ê°ì§€ë¨: {torch.cuda.get_device_name(0)}")
            device = "cuda"
            compute_type = "float16"
        else:
            device = "cpu"
            compute_type = "int8"

        try:
            self.model = WhisperModel(
                "large-v3",
                device=device,
                device_index=0,
                compute_type=compute_type,
                download_root="/app/models",
                num_workers=1,
                cpu_threads=0
            )
            print(f"âœ… {device.upper()} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            self.device = device

            # ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
            self.start_worker()
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def start_worker(self):
        """ì²˜ë¦¬ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘"""
        self.worker_thread = threading.Thread(target=self._process_audio_queue, daemon=True)
        self.worker_thread.start()
        print("ğŸ”§ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì›Œì»¤ ì‹œì‘")

    def _process_audio_queue(self):
        """íì—ì„œ ì˜¤ë””ì˜¤ ì²˜ë¦¬ (ë°±ê·¸ë¼ìš´ë“œ)"""
        while True:
            try:
                audio_data, callback = self.processing_queue.get()
                if audio_data is not None:
                    # STT ì²˜ë¦¬
                    text_result = self._transcribe_chunk(audio_data)

                    if text_result and text_result.get("text"):
                        # í‚¤ì›Œë“œ ì¶”ì¶œ
                        keywords = self.keyword_extractor.extract_keywords(text_result["text"])
                        text_result["keywords"] = keywords

                    if callback:
                        callback(text_result)

            except Exception as e:
                print(f"âŒ ì›Œì»¤ ì˜¤ë¥˜: {e}")

    def is_hallucination(self, text):
        """Hallucination í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
        if not text:
            return False

        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ hallucination í™•ì¸
        for pattern in self.hallucination_patterns:
            if pattern in text:
                print(f"âš ï¸ Hallucination ê°ì§€: '{pattern}' in '{text}'")
                return True

        # ìµœê·¼ í…ìŠ¤íŠ¸ì™€ ë™ì¼í•œì§€ í™•ì¸ (ë°˜ë³µ ê°ì§€)
        if len(self.recent_texts) >= 3:
            # ìµœê·¼ 3ê°œ í…ìŠ¤íŠ¸ ì¤‘ 2ê°œ ì´ìƒ ë™ì¼í•˜ë©´ hallucination
            if self.recent_texts.count(text) >= 2:
                print(f"âš ï¸ ë°˜ë³µ ê°ì§€: '{text}'")
                return True

        return False

    def _transcribe_chunk(self, audio_data):
        """ì‹¤ì œ ì „ì‚¬ ì²˜ë¦¬"""
        if self.model is None:
            return None

        # ì˜¤ë””ì˜¤ ì •ê·œí™”
        audio_data = audio_data / np.max(np.abs(audio_data) + 1e-10)

        # ì˜¤ë””ì˜¤ ì—ë„ˆì§€ ê³„ì‚°
        energy = np.sqrt(np.mean(np.square(audio_data)))
        if energy < 0.005:  # ë„ˆë¬´ ì¡°ìš©í•œ ì˜¤ë””ì˜¤ëŠ” ìŠ¤í‚µ
            print(f"â­ï¸ ë„ˆë¬´ ì¡°ìš©í•œ ì˜¤ë””ì˜¤ ìŠ¤í‚µ (energy: {energy:.4f})")
            return None

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_file = f"/tmp/audio_{time.time()}.wav"
        sf.write(temp_file, audio_data, self.sample_rate)

        try:
            segments, info = self.model.transcribe(
                temp_file,
                language="ko",
                task="transcribe",
                beam_size=2,
                best_of=2,
                temperature=0.0,
                vad_filter=True,
                vad_parameters={
                    "threshold": 0.6,  # ë” ì—„ê²©í•˜ê²Œ
                    "min_speech_duration_ms": 400,  # ë” ê¸¸ê²Œ
                    "min_silence_duration_ms": 500,  # ë” ê¸¸ê²Œ
                    "speech_pad_ms": 30  # ë” ì§§ê²Œ
                },
                condition_on_previous_text=False,
                initial_prompt="ì‹¤ì‹œê°„ ëŒ€í™” ìŒì„± ì¸ì‹",  # í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                word_timestamps=False,
                no_speech_threshold=0.7,  # ë¬´ìŒ ì„ê³„ê°’ ì¶”ê°€
                compression_ratio_threshold=2.0  # ì••ì¶•ë¥  ì„ê³„ê°’
            )

            text = ""
            for segment in segments:
                # no_speech_prob í™•ì¸
                if hasattr(segment, 'no_speech_prob') and segment.no_speech_prob > 0.7:
                    continue
                text += segment.text

            text = text.strip().replace("  ", " ")

            # Hallucination ì²´í¬
            if self.is_hallucination(text):
                print(f"ğŸš« Hallucination í•„í„°ë§: {text}")
                return None

            # ìµœê·¼ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            self.recent_texts.append(text)
            if len(self.recent_texts) > 5:
                self.recent_texts.pop(0)

            # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ í•„í„°ë§
            if len(text) < 2:
                return None

            result = {
                "text": text,
                "language": info.language if info.language else "ko",
                "confidence": float(info.language_probability) if info.language_probability else 0.95,
                "device": self.device,
                "timestamp": time.time()
            }

            return result

        except Exception as e:
            print(f"âŒ Transcribe ì˜¤ë¥˜: {e}")
            return None
        finally:
            Path(temp_file).unlink(missing_ok=True)

    def process_audio_async(self, audio_data, callback):
        """ë¹„ë™ê¸° ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
        self.processing_queue.put((audio_data, callback))

# Whisper í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤
processor = WhisperProcessor()

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index_keywords.html')

@app.route('/api/config')
def get_config():
    """ì„¤ì • ì •ë³´ ì œê³µ"""
    return {
        'status': 'ready',
        'websocket': 'integrated',
        'device': processor.device,
        'gpu': torch.cuda.is_available(),
        'mode': 'keyword_extraction',
        'llm_enabled': True
    }

@sock.route('/ws')
def websocket(ws):
    """WebSocket ì—°ê²° ì²˜ë¦¬"""
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°")
    print(f"ğŸ“¡ í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë“œ í™œì„±í™”: {time.strftime('%Y-%m-%d %H:%M:%S')}")

    audio_buffer = []
    buffer_duration = 0
    max_buffer_duration = 1.5
    min_buffer_duration = 1.0
    last_result_text = ""

    def send_result(result):
        """ê²°ê³¼ ì „ì†¡ ì½œë°±"""
        nonlocal last_result_text
        if result and result.get("text") and result["text"] != last_result_text:
            response = {
                "type": "transcription",
                "text": result["text"],
                "keywords": result.get("keywords", []),
                "language": result.get("language", "ko"),
                "confidence": result.get("confidence", 0.95),
                "device": result.get("device", "cuda"),
                "timestamp": time.time()
            }
            try:
                ws.send(json.dumps(response, ensure_ascii=False))
                print(f"ğŸ“ í…ìŠ¤íŠ¸: {result['text'][:50]}...")
                print(f"ğŸ”‘ í‚¤ì›Œë“œ: {[k['word'] for k in result.get('keywords', [])]}")
                last_result_text = result["text"]
            except:
                pass

    while True:
        try:
            message = ws.receive()
            if message is None:
                break

            try:
                data = json.loads(message)

                if data.get("type") == "audio":
                    audio_base64 = data.get("data", "")
                    audio_bytes = base64.b64decode(audio_base64)
                    audio_chunk = np.frombuffer(audio_bytes, dtype=np.float32)
                    audio_buffer.extend(audio_chunk)

                    buffer_duration = len(audio_buffer) / 16000

                    if buffer_duration >= min_buffer_duration:
                        energy = np.sqrt(np.mean(np.square(audio_chunk)))

                        if energy > 0.01 or buffer_duration >= max_buffer_duration:
                            audio_array = np.array(audio_buffer)
                            processor.process_audio_async(audio_array, send_result)

                            overlap_samples = int(0.1 * 16000)
                            audio_buffer = audio_buffer[-overlap_samples:] if len(audio_buffer) > overlap_samples else []
                            buffer_duration = len(audio_buffer) / 16000

                elif data.get("type") == "config":
                    ws.send(json.dumps({
                        "type": "config_updated",
                        "language": "ko",
                        "device": processor.device,
                        "mode": "keyword_extraction"
                    }))

            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")

        except Exception as e:
            print(f"âŒ WebSocket ì˜¤ë¥˜: {e}")
            break

    print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ¤ STT + ğŸ¤– LLM í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œìŠ¤í…œ")
    print("Real-time STT with AI Keyword Extraction")
    print("=" * 60)

    if torch.cuda.is_available():
        print(f"ğŸ–¥ï¸ GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

    os.makedirs("templates", exist_ok=True)
    os.makedirs("static", exist_ok=True)

    processor.load_model()

    print(f"\nğŸŒ í†µí•© ì„œë²„ ì‹œì‘: http://localhost:5000")
    print(f"ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ í™œì„±í™”")
    print("WebSocketì€ /ws ê²½ë¡œì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n")

    app.run(host='0.0.0.0', port=5000, debug=False)

if __name__ == "__main__":
    main()