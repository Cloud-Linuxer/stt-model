#!/usr/bin/env python3
"""
GPU ìµœì í™” ì‹¤ì‹œê°„ STT ì›¹ ì„œë²„
"""

import os
import json
import numpy as np
import time
from pathlib import Path
from flask import Flask, render_template
from flask_cors import CORS
from flask_sock import Sock
from faster_whisper import WhisperModel
import base64
import io
import soundfile as sf
import torch

# Flask ì•± ìƒì„±
app = Flask(__name__, template_folder='templates', static_folder='static')
CORS(app, resources={r"/*": {"origins": "*"}})
sock = Sock(app)

class WhisperProcessor:
    """GPU ìµœì í™” Whisper ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.model = None
        self.device = "cuda"
        self.sample_rate = 16000

    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ”„ Faster-Whisper ëª¨ë¸ ë¡œë”© ì¤‘ (GPU ëª¨ë“œ)...")

        # GPU ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
        if torch.cuda.is_available():
            print(f"âœ… GPU ê°ì§€ë¨: {torch.cuda.get_device_name(0)}")
            print(f"ğŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            device = "cuda"
            compute_type = "float16"
        else:
            print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            device = "cpu"
            compute_type = "int8"

        try:
            self.model = WhisperModel(
                "large-v3",
                device=device,
                device_index=0,
                compute_type=compute_type,
                download_root="/app/models",
                num_workers=4 if device == "cpu" else 1,
                cpu_threads=8 if device == "cpu" else 0
            )
            print(f"âœ… {device.upper()} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            self.device = device
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def transcribe_audio(self, audio_data, sample_rate=16000):
        """ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (GPU ìµœì í™”)"""
        if self.model is None:
            return None

        # ì˜¤ë””ì˜¤ ì •ê·œí™”
        audio_data = audio_data / np.max(np.abs(audio_data) + 1e-10)

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_file = f"/tmp/audio_{time.time()}.wav"
        sf.write(temp_file, audio_data, sample_rate)

        try:
            # GPU ìµœì í™” ì„¤ì •ìœ¼ë¡œ Transcribe
            segments, info = self.model.transcribe(
                temp_file,
                language="ko",  # í•œêµ­ì–´ ê¸°ë³¸
                task="transcribe",
                beam_size=5,
                best_of=5,
                temperature=0.0,
                vad_filter=True,
                vad_parameters={
                    "threshold": 0.5,
                    "min_speech_duration_ms": 250,
                    "min_silence_duration_ms": 500,
                    "speech_pad_ms": 200
                },
                condition_on_previous_text=False,
                initial_prompt=None,
            )

            # ê²°ê³¼ ìˆ˜ì§‘
            text = ""
            for segment in segments:
                text += segment.text

            # í›„ì²˜ë¦¬
            text = text.strip().replace("  ", " ")

            result = {
                "text": text,
                "language": info.language if info.language else "ko",
                "confidence": float(info.language_probability) if info.language_probability else 0.95,
                "device": self.device
            }

            return result

        except Exception as e:
            print(f"âŒ Transcribe ì˜¤ë¥˜: {e}")
            return None
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            Path(temp_file).unlink(missing_ok=True)

# Whisper í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤
processor = WhisperProcessor()

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index_fixed.html')

@app.route('/api/config')
def get_config():
    """ì„¤ì • ì •ë³´ ì œê³µ"""
    return {
        'status': 'ready',
        'websocket': 'integrated',
        'device': processor.device,
        'gpu': torch.cuda.is_available()
    }

@sock.route('/ws')
def websocket(ws):
    """WebSocket ì—°ê²° ì²˜ë¦¬"""
    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°")

    audio_buffer = []
    buffer_duration = 0
    max_buffer_duration = 2.0  # 2ì´ˆë§ˆë‹¤ ì²˜ë¦¬

    while True:
        try:
            message = ws.receive()
            if message is None:
                break

            # JSON ë©”ì‹œì§€ ì²˜ë¦¬
            try:
                data = json.loads(message)

                if data.get("type") == "audio":
                    # Base64 ì˜¤ë””ì˜¤ ë°ì´í„° ë””ì½”ë“œ
                    audio_base64 = data.get("data", "")
                    audio_bytes = base64.b64decode(audio_base64)

                    # Float32 ë°°ì—´ë¡œ ë³€í™˜
                    audio_chunk = np.frombuffer(audio_bytes, dtype=np.float32)
                    audio_buffer.extend(audio_chunk)

                    # ë²„í¼ ì‹œê°„ ê³„ì‚°
                    buffer_duration = len(audio_buffer) / 16000

                    # 2ì´ˆ ì´ìƒ ìŒ“ì´ë©´ ì²˜ë¦¬
                    if buffer_duration >= max_buffer_duration:
                        audio_array = np.array(audio_buffer)

                        # Whisperë¡œ ì²˜ë¦¬
                        result = processor.transcribe_audio(audio_array, 16000)

                        if result and result["text"]:
                            # ê²°ê³¼ ì „ì†¡
                            response = {
                                "type": "transcription",
                                "text": result["text"],
                                "language": result["language"],
                                "confidence": result["confidence"],
                                "device": result["device"],
                                "timestamp": time.time()
                            }
                            ws.send(json.dumps(response, ensure_ascii=False))
                            print(f"ğŸ“ [{result['device'].upper()}] {result['language']}: {result['text']}")

                        # ë²„í¼ ì´ˆê¸°í™”
                        audio_buffer = []
                        buffer_duration = 0

                elif data.get("type") == "config":
                    # ì„¤ì • ì—…ë°ì´íŠ¸
                    ws.send(json.dumps({
                        "type": "config_updated",
                        "language": "ko",
                        "device": processor.device
                    }))

            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")

        except Exception as e:
            print(f"âŒ WebSocket ì˜¤ë¥˜: {e}")
            break

    print(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ¤ GPU ìµœì í™” ì‹¤ì‹œê°„ STT ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜")
    print("GPU-Optimized Real-time Speech-to-Text")
    print("=" * 60)

    # GPU ì •ë³´ ì¶œë ¥
    if torch.cuda.is_available():
        print(f"ğŸ–¥ï¸ GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("templates", exist_ok=True)
    os.makedirs("static", exist_ok=True)

    # ëª¨ë¸ ë¡œë“œ
    processor.load_model()

    # Flask + WebSocket ì„œë²„ ì‹œì‘
    print(f"\nğŸŒ STT ì„œë²„ ì‹œì‘: http://localhost:5000")
    print(f"ğŸ–¥ï¸ Device: {processor.device.upper()}")
    print("WebSocketì€ /ws ê²½ë¡œì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n")

    app.run(host='0.0.0.0', port=5000, debug=False)

if __name__ == "__main__":
    main()