#!/usr/bin/env python3
"""
STT + LLM í‚¤ì›Œë“œ ì¶”ì¶œ í†µí•© ì„œë²„ - Stable Version
- Error handling for CUDNN issues
- Fallback to CPU if GPU fails
- Graceful error recovery
"""

import json
import time
import torch
import numpy as np
import soundfile as sf
import os
import requests
import base64
from flask import Flask, render_template, request, jsonify
from flask_sock import Sock
from faster_whisper import WhisperModel
import warnings
import re
import traceback
warnings.filterwarnings("ignore")

# í™˜ê²½ ë³€ìˆ˜
VLLM_API_URL = os.getenv("VLLM_API_URL", "http://localhost:8000/v1/completions")

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key'
sock = Sock(app)

# ì „ì—­ ë³€ìˆ˜
stt_processor = None
keyword_extractor = None

class StreamingSTT:
    """ìŠ¤íŠ¸ë¦¬ë° STT ì²˜ë¦¬ - Stable Version"""

    def __init__(self):
        self.model = None
        self.device = None
        self.audio_buffer = []
        self.process_interval = 16000  # 1ì´ˆë§ˆë‹¤ ì²˜ë¦¬ (16kHz)
        self.use_gpu = False

        # í• ë£¨ì‹œë„¤ì´ì…˜ íŒ¨í„´
        self.hallucination_patterns = [
            "ê°ì‚¬í•©ë‹ˆë‹¤", "ì‹œì²­í•´ì£¼ì…”ì„œ", "êµ¬ë…", "ì¢‹ì•„ìš”",
            "MBC ë‰´ìŠ¤", "KBS ë‰´ìŠ¤", "ë‹¤ìŒ ì˜ìƒ", "ì˜ìƒí¸ì§‘"
        ]

    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ - GPU ì‹¤íŒ¨ì‹œ CPU í´ë°±"""
        print("ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘...")

        # Try GPU first with error handling
        try:
            if torch.cuda.is_available():
                print(f"âœ… GPU ê°ì§€ë¨: {torch.cuda.get_device_name(0)}")
                print("ğŸ”„ GPU ëª¨ë¸ ë¡œë“œ ì‹œë„...")

                # Try to load with GPU
                self.model = WhisperModel(
                    "medium",
                    device="cuda",
                    device_index=0,
                    compute_type="float16",
                    download_root="/app/models",
                    num_workers=1,
                    cpu_threads=0
                )

                # Test the model with a small audio
                test_audio = np.zeros(16000, dtype=np.float32)
                test_file = "/tmp/test_model.wav"
                sf.write(test_file, test_audio, 16000)

                # Try a test transcription
                segments, _ = self.model.transcribe(
                    test_file,
                    language="ko",
                    vad_filter=False
                )
                # Consume the generator to test
                for _ in segments:
                    break

                os.remove(test_file)
                self.device = "cuda"
                self.use_gpu = True
                print("âœ… GPU ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
                return True

        except Exception as e:
            print(f"âš ï¸ GPU ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ”„ CPU ëª¨ë“œë¡œ í´ë°±...")

        # Fallback to CPU
        try:
            self.model = WhisperModel(
                "medium",
                device="cpu",
                compute_type="int8",
                download_root="/app/models",
                num_workers=1,
                cpu_threads=4
            )
            self.device = "cpu"
            self.use_gpu = False
            print("âœ… CPU ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            return True

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def process_stream(self, audio_chunk):
        """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ - ë¬´ì¡°ê±´ ë²„í¼ì— ì¶”ê°€"""
        if self.model is None:
            return None

        # ë²„í¼ì— ì¶”ê°€
        self.audio_buffer.extend(audio_chunk)

        # ë””ë²„ê·¸ ë¡œê·¸ (ë§¤ 10ë²ˆì§¸ ì²­í¬ë§Œ)
        if len(self.audio_buffer) % 16000 == 0:
            print(f"ğŸ“Š Buffer: {len(self.audio_buffer)} samples")

        # 1ì´ˆ ì´ìƒ ëª¨ì´ë©´ ì²˜ë¦¬
        if len(self.audio_buffer) >= self.process_interval:
            return self._process_buffer()

        return None

    def _process_buffer(self):
        """ë²„í¼ ì²˜ë¦¬ - ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”"""
        if not self.audio_buffer or len(self.audio_buffer) < 4800:  # ìµœì†Œ 0.3ì´ˆ
            self.audio_buffer = []
            return None

        print(f"ğŸ¯ Processing {len(self.audio_buffer)} samples...")

        # ë²„í¼ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        audio_data = np.array(self.audio_buffer, dtype=np.float32)

        # ì •ê·œí™”
        max_val = np.max(np.abs(audio_data))
        if max_val > 0:
            audio_data = audio_data / max_val

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_file = f"/tmp/audio_{time.time()}.wav"

        try:
            sf.write(temp_file, audio_data, 16000)

            # Whisper ì²˜ë¦¬ with error handling
            print(f"ğŸ”Š Running Whisper transcription ({self.device})...")

            segments, info = self.model.transcribe(
                temp_file,
                language="ko",
                beam_size=3 if self.device == "cpu" else 5,
                best_of=3 if self.device == "cpu" else 5,
                patience=1,
                length_penalty=1,
                temperature=[0.0],
                compression_ratio_threshold=2.4,
                log_prob_threshold=-1.0,
                no_speech_threshold=0.6,
                condition_on_previous_text=False,
                word_timestamps=False,
                vad_filter=False
            )

            # ì „ì‚¬ ê²°ê³¼ ìˆ˜ì§‘
            full_text = []
            for segment in segments:
                text = segment.text.strip()
                if text and not self._is_hallucination(text):
                    full_text.append(text)
                    print(f"ğŸ“ Segment: {text}")

            # ë²„í¼ ì´ˆê¸°í™”
            self.audio_buffer = []

            if full_text:
                result_text = " ".join(full_text)
                print(f"âœ… Transcription: {result_text}")
                return {
                    "text": result_text,
                    "language": info.language if info else "ko",
                    "timestamp": time.time(),
                    "device": self.device
                }
            else:
                print("âš ï¸ No valid text from Whisper")

        except Exception as e:
            print(f"âŒ Whisper ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            print(f"ğŸ“‹ Error details: {traceback.format_exc()}")

            # GPU ì—ëŸ¬ì‹œ CPUë¡œ ì¬ì‹œë„
            if self.use_gpu and "cudnn" in str(e).lower():
                print("ğŸ”„ GPU ì—ëŸ¬ ê°ì§€, CPUë¡œ ì¬ì‹œë„...")
                self.use_gpu = False
                self.device = "cpu"

                # ëª¨ë¸ ì¬ë¡œë“œ (CPU)
                try:
                    self.model = WhisperModel(
                        "medium",
                        device="cpu",
                        compute_type="int8",
                        download_root="/app/models",
                        num_workers=1,
                        cpu_threads=4
                    )
                    print("âœ… CPU ëª¨ë¸ë¡œ ì „í™˜ ì™„ë£Œ")

                    # CPUë¡œ ì¬ì‹œë„
                    return self._process_buffer()

                except Exception as cpu_error:
                    print(f"âŒ CPU í´ë°± ì‹¤íŒ¨: {cpu_error}")

            # ë²„í¼ ì´ˆê¸°í™”
            self.audio_buffer = []

        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass

        return None

    def _is_hallucination(self, text):
        """í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬"""
        for pattern in self.hallucination_patterns:
            if pattern in text:
                return True
        return False

class KeywordExtractor:
    """í‚¤ì›Œë“œ ì¶”ì¶œ (LLM ì‚¬ìš©)"""

    def __init__(self):
        self.min_importance = 0.3
        self.vllm_url = VLLM_API_URL

    def extract_keywords(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text or len(text) < 5:
            return []

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: "{text}"

ì‘ë‹µ í˜•ì‹:
{{
    "keywords": [
        {{"keyword": "ë‹¨ì–´1", "importance": 0.9}},
        {{"keyword": "ë‹¨ì–´2", "importance": 0.7}}
    ]
}}

í‚¤ì›Œë“œ:"""

        try:
            response = requests.post(
                self.vllm_url,
                json={
                    "model": "Qwen/Qwen2.5-7B-Instruct",
                    "prompt": prompt,
                    "max_tokens": 100,
                    "temperature": 0.1,
                    "stop": ["}", "}}"]
                },
                timeout=5
            )

            if response.status_code == 200:
                text_response = response.json()['choices'][0]['text']

                # JSON íŒŒì‹± ì‹œë„
                json_pattern = r'\{[^{}]*"keywords"[^{}]*\[[^\]]*\][^{}]*\}'
                json_match = re.search(json_pattern, text_response, re.DOTALL)

                if json_match:
                    data = json.loads(json_match.group(0))
                    keywords = data.get('keywords', [])
                    return [k for k in keywords if k.get('importance', 0) >= self.min_importance]

        except Exception as e:
            print(f"âš ï¸ LLM í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")

        return []

# WebSocket í•¸ë“¤ëŸ¬
@sock.route('/ws')
def websocket(ws):
    """WebSocket ì—°ê²° ì²˜ë¦¬"""
    print(f"ğŸ”Œ ìƒˆ WebSocket ì—°ê²°: {request.remote_addr}")

    # ì „ì—­ ë³€ìˆ˜ë¡œ ë¯¸ë¦¬ ë¡œë“œëœ ëª¨ë¸ ì‚¬ìš©
    global stt_processor, keyword_extractor

    if stt_processor is None:
        streaming_stt = StreamingSTT()
        if not streaming_stt.load_model():
            ws.send(json.dumps({"type": "error", "message": "Model load failed"}))
            return
        stt_processor = streaming_stt
    else:
        streaming_stt = stt_processor

    if keyword_extractor is None:
        keyword_extractor = KeywordExtractor()

    audio_buffer = []
    process_chunk_size = 1600  # 100ms ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    connection_active = True
    packet_count = 0

    try:
        while connection_active:
            try:
                message = ws.receive(timeout=1)
                if message is None:
                    continue

                data = json.loads(message)

                if data.get('type') == 'audio':
                    # Base64 ì˜¤ë””ì˜¤ ë°ì´í„° ë””ì½”ë”©
                    try:
                        audio_bytes = base64.b64decode(data['data'])

                        # Float32 ë°°ì—´ë¡œ ë³€í™˜
                        audio_array = np.frombuffer(audio_bytes, dtype=np.float32)

                        packet_count += 1
                        if packet_count % 100 == 1:
                            print(f"ğŸµ Audio packet #{packet_count}: size={len(audio_array)}")

                        # ë²„í¼ì— ì¶”ê°€
                        audio_buffer.extend(audio_array)

                        # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ëª¨ì´ë©´ ì²˜ë¦¬
                        while len(audio_buffer) >= process_chunk_size:
                            chunk = audio_buffer[:process_chunk_size]
                            audio_buffer = audio_buffer[process_chunk_size:]

                            # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                            result = streaming_stt.process_stream(chunk)

                            if result:
                                print(f"âœ… ì „ì‚¬ ì™„ë£Œ: {result['text']}")

                                # í‚¤ì›Œë“œ ì¶”ì¶œ
                                keywords = keyword_extractor.extract_keywords(result['text'])
                                result['keywords'] = keywords

                                # ê²°ê³¼ ì „ì†¡
                                ws.send(json.dumps({
                                    "type": "transcription",
                                    **result
                                }))

                    except Exception as e:
                        print(f"âš ï¸ ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        # ì—ëŸ¬ë¥¼ í´ë¼ì´ì–¸íŠ¸ì— ì „ë‹¬í•˜ì§€ ì•Šê³  ê³„ì† ì²˜ë¦¬

                elif data.get('type') == 'config':
                    # ì„¤ì • ë©”ì‹œì§€ ì²˜ë¦¬
                    print(f"ğŸ“‹ ì„¤ì • ìˆ˜ì‹ : {data}")

            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            except TimeoutError:
                # íƒ€ì„ì•„ì›ƒì€ ì •ìƒ - ê³„ì† ì§„í–‰
                pass
            except Exception as e:
                if "Connection closed" in str(e):
                    connection_active = False
                else:
                    print(f"âš ï¸ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    except Exception as e:
        print(f"âŒ WebSocket ì˜¤ë¥˜: {e}")
    finally:
        print(f"ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ: {request.remote_addr}")

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index_keywords_scroll_fixed.html')

@app.route('/api/config', methods=['GET'])
def get_config():
    """ì„¤ì • ì •ë³´"""
    global stt_processor

    device = "unknown"
    gpu_available = torch.cuda.is_available()

    if stt_processor:
        device = stt_processor.device
    elif gpu_available:
        device = "cuda"
    else:
        device = "cpu"

    return jsonify({
        "sample_rate": 16000,
        "language": "ko",
        "model": "medium",
        "device": device,
        "gpu": gpu_available,
        "llm_enabled": True,
        "mode": "streaming",
        "buffer_mode": True,
        "stable_version": True
    })

@app.route('/api/test-audio', methods=['POST'])
def test_audio():
    """ì˜¤ë””ì˜¤ íŒŒì¼ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    global stt_processor, keyword_extractor

    if stt_processor is None:
        stt_processor = StreamingSTT()
        if not stt_processor.load_model():
            return jsonify({"error": "Model load failed"}), 500

    if keyword_extractor is None:
        keyword_extractor = KeywordExtractor()

    # íŒŒì¼ ë°›ê¸°
    if 'audio' not in request.files:
        return jsonify({"error": "No audio file"}), 400

    audio_file = request.files['audio']

    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    temp_path = f"/tmp/test_{time.time()}.wav"
    audio_file.save(temp_path)

    try:
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio_data, sr = sf.read(temp_path)

        # 16kHzë¡œ ë¦¬ìƒ˜í”Œë§ (í•„ìš”í•œ ê²½ìš°)
        if sr != 16000:
            from scipy import signal
            audio_data = signal.resample(audio_data, int(len(audio_data) * 16000 / sr))

        # í”„ë¡œì„¸ì‹±
        stt_processor.audio_buffer = list(audio_data)
        result = stt_processor._process_buffer()

        if result:
            keywords = keyword_extractor.extract_keywords(result['text'])
            result['keywords'] = keywords
            return jsonify(result)
        else:
            return jsonify({"error": "No transcription"}), 500

    except Exception as e:
        print(f"âŒ Test audio error: {e}")
        return jsonify({"error": str(e)}), 500

    finally:
        if os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except:
                pass

@app.route('/api/health', methods=['GET'])
def health():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    global stt_processor

    status = {
        "status": "healthy",
        "model_loaded": stt_processor is not None,
        "gpu_available": torch.cuda.is_available()
    }

    if stt_processor:
        status["device"] = stt_processor.device
        status["use_gpu"] = stt_processor.use_gpu

    return jsonify(status)

if __name__ == '__main__':
    print("\n" + "="*60)
    print("ğŸ¤ STT ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ (Stable Version)")
    print("="*60 + "\n")

    if torch.cuda.is_available():
        print(f"ğŸ–¥ï¸ GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    else:
        print("ğŸ’» CPU ëª¨ë“œë¡œ ì‹¤í–‰")

    # ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ
    print("\nğŸš€ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    stt_processor = StreamingSTT()
    if stt_processor.load_model():
        keyword_extractor = KeywordExtractor()
        print("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\n")
    else:
        print("âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ëŸ°íƒ€ì„ì— ì¬ì‹œë„í•©ë‹ˆë‹¤.\n")
        stt_processor = None

    # ì„œë²„ ì‹œì‘
    print(f"ğŸŒ ì„œë²„ ì‹œì‘: http://localhost:5000")
    print(f"ğŸ’ª Stable Version - Error Recovery Enabled")
    print(f"ğŸ”Œ WebSocket ì—”ë“œí¬ì¸íŠ¸: ws://localhost:5000/ws")
    print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸: POST /api/test-audio")
    print(f"â¤ï¸ í—¬ìŠ¤ ì²´í¬: GET /api/health")
    print("="*60 + "\n")

    app.run(host='0.0.0.0', port=5000, debug=False)