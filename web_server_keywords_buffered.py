#!/usr/bin/env python3
"""
STT + LLM í‚¤ì›Œë“œ ì¶”ì¶œ í†µí•© ì„œë²„ (ë²„í¼ë§ ê°œì„  ë²„ì „)
- STTëŠ” ì‹¤ì‹œê°„ ì²­í¬ ì²˜ë¦¬
- LLMì€ ë²„í¼ì— ëª¨ì¸ í…ìŠ¤íŠ¸ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬
"""

import json
import time
import torch
import numpy as np
import soundfile as sf
import threading
import queue
import os
import requests
from collections import deque
from flask import Flask, render_template, request, jsonify
from flask_sock import Sock
from faster_whisper import WhisperModel
import warnings
warnings.filterwarnings("ignore")

# í™˜ê²½ ë³€ìˆ˜
VLLM_API_URL = os.getenv("VLLM_API_URL", "http://localhost:8000/v1/completions")

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key'
sock = Sock(app)

# ì „ì—­ ë³€ìˆ˜
stt_processor = None
keyword_extractor = None

class KeywordExtractor:
    """LLMì„ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ í´ë˜ìŠ¤ (ë²„í¼ë§)"""

    def __init__(self):
        self.api_url = VLLM_API_URL
        self.min_importance = 0.8

        # í…ìŠ¤íŠ¸ ë²„í¼ ê´€ë¦¬
        self.text_buffer = deque(maxlen=10)  # ìµœê·¼ 10ê°œ ë¬¸ì¥ ì €ì¥
        self.buffer_lock = threading.Lock()
        self.last_extraction_time = time.time()
        self.extraction_interval = 5.0  # 5ì´ˆë§ˆë‹¤ í‚¤ì›Œë“œ ì¶”ì¶œ

    def add_to_buffer(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ ë²„í¼ì— ì¶”ê°€ (í• ë£¨ì‹œë„¤ì´ì…˜ í…ìŠ¤íŠ¸ëŠ” ì œì™¸)"""
        if not text or len(text.strip()) <= 5:
            return

        # í• ë£¨ì‹œë„¤ì´ì…˜ íŒ¨í„´ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ëŠ” ë²„í¼ì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ
        hallucination_patterns = [
            "ì˜ìƒí¸ì§‘ ë°•ì§„ì£¼", "ê°ì‚¬í•©ë‹ˆë‹¤", "ì‹œì²­í•´ì£¼ì…”ì„œ",
            "ì´ ì‹œê° ì„¸ê³„ì˜€ìŠµë‹ˆë‹¤", "MBC ë‰´ìŠ¤", "KBS ë‰´ìŠ¤"
        ]

        for pattern in hallucination_patterns:
            if pattern in text:
                print(f"âš ï¸ ë²„í¼ ì¶”ê°€ ì°¨ë‹¨ (í• ë£¨ì‹œë„¤ì´ì…˜): {text}")
                return

        with self.buffer_lock:
            self.text_buffer.append(text)

    def should_extract(self):
        """í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì  í™•ì¸"""
        current_time = time.time()
        # 5ì´ˆ ê²½ê³¼ ë˜ëŠ” ë²„í¼ê°€ ì¶©ë¶„íˆ ì°¬ ê²½ìš°
        return (current_time - self.last_extraction_time >= self.extraction_interval
                or len(self.text_buffer) >= 5)

    def extract_keywords_from_buffer(self):
        """ë²„í¼ì˜ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        with self.buffer_lock:
            if not self.text_buffer:
                return []

            # ë²„í¼ì˜ í…ìŠ¤íŠ¸ë¥¼ ê²°í•© (ìµœëŒ€ 5ê°œ ë¬¸ì¥)
            recent_texts = list(self.text_buffer)[-5:]
            combined_text = " ".join(recent_texts)
            self.last_extraction_time = time.time()

        # ì¶©ë¶„í•œ í…ìŠ¤íŠ¸ê°€ ëª¨ì˜€ì„ ë•Œë§Œ ì¶”ì¶œ
        if len(combined_text) < 30:
            return []

        return self.extract_keywords(combined_text)

    def extract_keywords(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text or len(text.strip()) < 10:
            return []

        # í‚¤ì›Œë“œ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì „ì²´ ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì¤‘ìš”í•œ ëª…ì‚¬ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

í…ìŠ¤íŠ¸: "{text}"

ì¶”ì¶œ ê·œì¹™:
1. ë°˜ë“œì‹œ ëª…ì‚¬ë§Œ ì¶”ì¶œ (ì‚¬ëŒ, ì¥ì†Œ, íšŒì‚¬, ì œí’ˆ, ê¸°ìˆ , ì¥ë¹„, ì„œë¹„ìŠ¤ ì´ë¦„)
2. ë™ì‚¬ëŠ” ì ˆëŒ€ ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš” (ê°€ë‹¤, ë“£ë‹¤, ìˆë‹¤, í•˜ë‹¤, ë˜ë‹¤, ë¯¸ì¹˜ë‹¤ ë“± ê¸ˆì§€)
3. ë™ì‚¬ì˜ ì–´ê°„ì´ë‚˜ ì–´ë¯¸ë„ ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš” (ë“£ê³ , ê°€ê³ , ìˆëŠ”, ë˜ëŠ” ë“± ê¸ˆì§€)
4. êµ¬ì²´ì ì¸ ëŒ€ìƒì„ ì§€ì¹­í•˜ëŠ” ëª…ì‚¬ë§Œ ì¶”ì¶œ
5. ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ, ê°€ì¥ í•µì‹¬ì ì¸ ëª…ì‚¬ë§Œ
6. ì „ì²´ ë¬¸ë§¥ì—ì„œ ë°˜ë³µë˜ê±°ë‚˜ ì¤‘ìš”í•œ ì£¼ì œë¥¼ ìš°ì„  ì¶”ì¶œ

ì ˆëŒ€ ì¶”ì¶œí•˜ë©´ ì•ˆ ë˜ëŠ” ê²ƒë“¤:
- ë™ì‚¬ì™€ ê·¸ í™œìš©í˜•: ë“£ë‹¤, ë“£ê³ , ê°€ë‹¤, ê°€ê³ , ìˆë‹¤, ìˆëŠ”, ë˜ë‹¤, ë˜ëŠ”, í•˜ë‹¤, í•˜ëŠ”, ë¯¸ì¹˜ë‹¤, ë¯¸ì¹˜ëŠ”
- ì¡°ì‚¬: ì€, ëŠ”, ì´, ê°€, ì„, ë¥¼, ì—, ì—ì„œ, ë¡œ, ì™€, ê³¼, ë„, ë§Œ, ê¹Œì§€
- ëŒ€ëª…ì‚¬: ë‚˜, ë„ˆ, ìš°ë¦¬, ê·¸ê²ƒ, ì´ê²ƒ, ì €ê²ƒ
- ê°ì •í‘œí˜„: ã…‹, ã…, ã… 

JSON ì‘ë‹µ:
{{
  "keywords": [
    {{"word": "ëª…ì‚¬1", "importance": 0.9, "category": "ì¹´í…Œê³ ë¦¬"}},
    {{"word": "ëª…ì‚¬2", "importance": 0.8, "category": "ì¹´í…Œê³ ë¦¬"}}
  ]
}}

ì¹´í…Œê³ ë¦¬: ì¸ë¬¼, ì¥ì†Œ, íšŒì‚¬, ê¸°ìˆ , ì œí’ˆ, ì¥ë¹„, ì„œë¹„ìŠ¤, ê¸°íƒ€
ì¤‘ìš”ë„: 0.8 ì´ìƒë§Œ (ë§¤ìš° ì¤‘ìš”í•œ ëª…ì‚¬ë§Œ)

í…ìŠ¤íŠ¸ê°€ ì§§ê±°ë‚˜ ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜.
ì‘ë‹µ:"""

        try:
            response = requests.post(
                self.api_url,
                json={
                    "model": "Qwen/Qwen2.5-7B-Instruct",
                    "prompt": prompt,
                    "max_tokens": 200,
                    "temperature": 0.1,
                    "stop": ["}}", "\n\n"]
                },
                timeout=5
            )

            if response.status_code == 200:
                result = response.json()
                text_response = result['choices'][0]['text']

                # JSON íŒŒì‹±
                try:
                    # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    import re

                    # JSON íŒ¨í„´ ì°¾ê¸°
                    json_pattern = r'\{[^{}]*"keywords"[^{}]*\[[^\]]*\][^{}]*\}'
                    json_match = re.search(json_pattern, text_response, re.DOTALL)

                    if json_match:
                        json_text = json_match.group(0)
                    else:
                        # ê¸°ë³¸ ë°©ë²• ì‹œë„
                        if '{' in text_response:
                            json_start = text_response.index('{')
                            json_end = text_response.rfind('}')
                            if json_end > json_start:
                                json_text = text_response[json_start:json_end+1]
                            else:
                                json_text = text_response[json_start:] + '}'
                        else:
                            raise ValueError("No JSON found")

                    data = json.loads(json_text)
                    keywords = data.get('keywords', [])

                    # ì¤‘ìš”ë„ í•„í„°ë§
                    filtered = [k for k in keywords if k.get('importance', 0) >= self.min_importance]

                    # í‚¤ì›Œë“œ ë¡œê¹…
                    if filtered:
                        timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
                        print(f"\n{'='*60}")
                        print(f"ğŸ“ [{timestamp}] ì¶”ì¶œëœ í‚¤ì›Œë“œ (ë²„í¼ ê¸°ë°˜):")
                        print(f"   ì›ë³¸ í…ìŠ¤íŠ¸: {text[:150]}...")
                        print(f"   í‚¤ì›Œë“œ ëª©ë¡:")
                        for kw in filtered:
                            print(f"      - {kw['word']} ({kw.get('category', 'ê¸°íƒ€')}, ì¤‘ìš”ë„: {kw['importance']:.1f})")
                        print(f"{'='*60}\n")

                        # íŒŒì¼ë¡œë„ ë¡œê¹…
                        with open("/tmp/keywords_log.txt", "a", encoding="utf-8") as f:
                            f.write(f"\n[{timestamp}]\n")
                            f.write(f"í…ìŠ¤íŠ¸: {text}\n")
                            f.write(f"í‚¤ì›Œë“œ: {', '.join([k['word'] for k in filtered])}\n")
                            f.write("-" * 50 + "\n")

                    return filtered
                except json.JSONDecodeError:
                    print(f"JSON íŒŒì‹± ì‹¤íŒ¨: {text_response}")
                    return []

        except Exception as e:
            print(f"LLM í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

        return []

class STTProcessor:
    """STT ì²˜ë¦¬ í´ë˜ìŠ¤ (ì‹¤ì‹œê°„ ì²­í¬ ì²˜ë¦¬)"""

    def __init__(self, keyword_extractor):
        self.model = None
        self.device = None
        self.sample_rate = 16000
        self.processing_queue = queue.Queue()
        self.worker_thread = None
        self.keyword_extractor = keyword_extractor

        # Hallucination íŒ¨í„´ (ë¡œê·¸ ë¶„ì„ ê¸°ë°˜ ê°•í™”)
        self.hallucination_patterns = [
            "ì‹œì²­í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
            "êµ¬ë…ê³¼ ì¢‹ì•„ìš”",
            "ì•Œë¦¼ ì„¤ì •",
            "ë‹¤ìŒ ì˜ìƒì—ì„œ",
            "MBC ë‰´ìŠ¤",
            "KBS ë‰´ìŠ¤",
            "SBS ë‰´ìŠ¤",
            "YTN ë‰´ìŠ¤",
            "JTBC ë‰´ìŠ¤",
            "ì§€ê¸ˆê¹Œì§€",
            "ë‚ ì”¨ì…ë‹ˆë‹¤",
            "ë‰´ìŠ¤ íŠ¹ë³´",
            "ì†ë³´ì…ë‹ˆë‹¤",
            "ê¸°ìì…ë‹ˆë‹¤",
            "ì•µì»¤ì…ë‹ˆë‹¤",
            "ì˜ìƒí¸ì§‘ ë°•ì§„ì£¼",  # ë¡œê·¸ì—ì„œ ë°˜ë³µ í™•ì¸
            "ì´ ì‹œê° ì„¸ê³„ì˜€ìŠµë‹ˆë‹¤",  # ë¡œê·¸ì—ì„œ ë°˜ë³µ í™•ì¸
            "í•œê¸€ìë§‰ by",  # ìë§‰ ê´€ë ¨
            "ê¸°ìƒìºìŠ¤í„°",  # ë‚ ì”¨ ë°©ì†¡ ê´€ë ¨
            "ê¹€ì„±í˜„ì…ë‹ˆë‹¤",  # ë‰´ìŠ¤ ì•µì»¤ ì´ë¦„
            "ë°°í˜œì§€",  # ê¸°ìƒìºìŠ¤í„° ì´ë¦„
            "ìë§‰ ì œê³µ",  # ìë§‰ ê´€ë ¨
            "ìë§‰ì„ ì‚¬ìš©",  # ìë§‰ ê´€ë ¨
            "ë„¤ ê°ì‚¬í•©ë‹ˆë‹¤",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ê³ ìƒí•˜ì…¨ìŠµë‹ˆë‹¤",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ë‹¤ìŒ ì‹œê°„ì—",  # ë°©ì†¡ ì˜ˆê³ 
            "ë§Œë‚˜ìš”",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ëµ™ê² ìŠµë‹ˆë‹¤",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ì—¬ê¸°ê¹Œì§€",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ë§ˆë¬´ë¦¬",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ëìœ¼ë¡œ",  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
            "ì •ë¦¬í•˜ê² ìŠµë‹ˆë‹¤"  # ë°©ì†¡ ì¢…ë£Œ ë©˜íŠ¸
        ]

        self.recent_texts = []  # ìµœê·¼ ì¸ì‹ í…ìŠ¤íŠ¸ ì €ì¥

    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ”„ Whisper ëª¨ë¸ ë¡œë”© ì¤‘ (GPU ëª¨ë“œ)...")

        if torch.cuda.is_available():
            print(f"âœ… GPU ê°ì§€ë¨: {torch.cuda.get_device_name(0)}")
            device = "cuda"
            compute_type = "float16"
        else:
            device = "cpu"
            compute_type = "int8"

        try:
            self.model = WhisperModel(
                "large-v3",
                device=device,
                device_index=0,
                compute_type=compute_type,
                download_root="/app/models",
                num_workers=1,
                cpu_threads=0
            )
            print(f"âœ… {device.upper()} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            self.device = device

            # ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
            self.start_worker()

            # í‚¤ì›Œë“œ ì¶”ì¶œ íƒ€ì´ë¨¸ ì‹œì‘
            self.start_keyword_timer()

            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def start_worker(self):
        """ì²˜ë¦¬ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘"""
        self.worker_thread = threading.Thread(target=self._process_audio_queue, daemon=True)
        self.worker_thread.start()
        print("ğŸ”§ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì›Œì»¤ ì‹œì‘")

    def start_keyword_timer(self):
        """ì£¼ê¸°ì  í‚¤ì›Œë“œ ì¶”ì¶œ íƒ€ì´ë¨¸"""
        def extract_periodically():
            while True:
                time.sleep(5)  # 5ì´ˆë§ˆë‹¤ ì²´í¬
                if self.keyword_extractor.should_extract():
                    keywords = self.keyword_extractor.extract_keywords_from_buffer()
                    if keywords:
                        # ìµœì‹  ì½œë°±ì— í‚¤ì›Œë“œ ì „ì†¡
                        if hasattr(self, 'last_callback') and self.last_callback:
                            try:
                                self.last_callback({
                                    "keywords_update": True,
                                    "keywords": keywords
                                })
                            except:
                                pass

        timer_thread = threading.Thread(target=extract_periodically, daemon=True)
        timer_thread.start()
        print("â±ï¸ í‚¤ì›Œë“œ ì¶”ì¶œ íƒ€ì´ë¨¸ ì‹œì‘")

    def _process_audio_queue(self):
        """íì—ì„œ ì˜¤ë””ì˜¤ ì²˜ë¦¬ (ë°±ê·¸ë¼ìš´ë“œ)"""
        while True:
            try:
                audio_data, callback = self.processing_queue.get()
                if audio_data is not None:
                    # STT ì²˜ë¦¬ (ì‹¤ì‹œê°„)
                    text_result = self._transcribe_chunk(audio_data)

                    if text_result and text_result.get("text"):
                        # í…ìŠ¤íŠ¸ë¥¼ ë²„í¼ì— ì¶”ê°€
                        self.keyword_extractor.add_to_buffer(text_result["text"])

                        # ì½œë°± ì €ì¥ (ë‚˜ì¤‘ì— í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸ìš©)
                        self.last_callback = callback

                        # ì¦‰ì‹œ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡ (í‚¤ì›Œë“œ ì—†ì´)
                        text_result["keywords"] = []  # ì¼ë‹¨ ë¹ˆ ë°°ì—´

                    if callback:
                        callback(text_result)

            except Exception as e:
                print(f"âŒ ì›Œì»¤ ì˜¤ë¥˜: {e}")

    def is_hallucination(self, text):
        """Hallucination í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
        if not text:
            return False

        # ë‹¨ì–´ ì •ê·œí™” (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜)
        normalized = text.strip().lower()

        # ë‹¨ì¼ ì¸ì‚¬ë§/ê°ì‚¬ë§ í•„í„°ë§
        single_greetings = [
            "ê°ì‚¬í•©ë‹ˆë‹¤", "ê³ ë§™ìŠµë‹ˆë‹¤", "ê°ì‚¬ë“œë¦½ë‹ˆë‹¤",
            "ê³ ë§ˆì›Œìš”", "ê°ì‚¬í•´ìš”", "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤",
            "ë„¤", "ì˜ˆ", "ì•„ë‹ˆìš”", "ì•„ë‹ˆì˜¤", "ì‘", "ì–´",
            "ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•", "ì•ˆë…•íˆ", "ë„¤ ê°ì‚¬í•©ë‹ˆë‹¤"
        ]

        # ì •í™•íˆ ë‹¨ì¼ ì¸ì‚¬ë§ë§Œ ìˆëŠ” ê²½ìš°
        if normalized in [g.lower() for g in single_greetings]:
            if len(normalized) < 10:  # ì§§ì€ ë‹¨ì¼ ì¸ì‚¬ë§
                print(f"âš ï¸ ë‹¨ì¼ ì¸ì‚¬ë§ í•„í„°ë§: {text}")
                return True

        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ hallucination í™•ì¸
        for pattern in self.hallucination_patterns:
            if pattern in text:
                print(f"âš ï¸ Hallucination ê°ì§€: '{pattern}' in '{text}'")
                return True

        # ìµœê·¼ í…ìŠ¤íŠ¸ì™€ ë™ì¼í•œì§€ í™•ì¸ (ë°˜ë³µ ê°ì§€)
        if len(self.recent_texts) >= 3:
            if self.recent_texts.count(text) >= 2:
                print(f"âš ï¸ ë°˜ë³µ ê°ì§€: '{text}'")
                return True

        return False

    def _transcribe_chunk(self, audio_data):
        """ì‹¤ì œ ì „ì‚¬ ì²˜ë¦¬"""
        if self.model is None:
            return None

        # ì˜¤ë””ì˜¤ ì •ê·œí™”
        audio_data = audio_data / np.max(np.abs(audio_data) + 1e-10)

        # ì˜¤ë””ì˜¤ ì—ë„ˆì§€ ê³„ì‚° (ë” ì—„ê²©í•œ ì„ê³„ê°’)
        energy = np.sqrt(np.mean(np.square(audio_data)))
        if energy < 0.01:  # ì„ê³„ê°’ì„ 0.005ì—ì„œ 0.01ë¡œ ìƒí–¥
            print(f"â­ï¸ ë„ˆë¬´ ì¡°ìš©í•œ ì˜¤ë””ì˜¤ ìŠ¤í‚µ (energy: {energy:.4f})")
            return None

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_file = f"/tmp/audio_{time.time()}.wav"
        sf.write(temp_file, audio_data, self.sample_rate)

        try:
            segments, info = self.model.transcribe(
                temp_file,
                language="ko",
                beam_size=5,
                vad_filter=True,
                vad_parameters=dict(
                    threshold=0.6,  # ë” ë†’ì€ ìŒì„± ê°ì§€ ì„ê³„ê°’
                    min_speech_duration_ms=500,  # ìµœì†Œ ìŒì„± ì§€ì† ì‹œê°„ ì¦ê°€
                    max_speech_duration_s=30,  # ìµœëŒ€ ìŒì„± ê¸¸ì´ ì œí•œ
                    min_silence_duration_ms=800,  # ë” ê¸´ ì¹¨ë¬µ ê°ì§€
                    speech_pad_ms=100  # íŒ¨ë”© ê°ì†Œ
                ),
                without_timestamps=True,
                # í• ë£¨ì‹œë„¤ì´ì…˜ ì–µì œ íŒŒë¼ë¯¸í„° ì¶”ê°€
                suppress_blank=True,
                suppress_tokens=[-1],  # íŠ¹ìˆ˜ í† í° ì–µì œ
                condition_on_previous_text=False  # ì´ì „ í…ìŠ¤íŠ¸ì— ì¡°ê±´í™” í•˜ì§€ ì•ŠìŒ
            )

            text = "".join([segment.text for segment in segments]).strip()

            if text:
                # Hallucination ì²´í¬
                if self.is_hallucination(text):
                    print(f"âš ï¸ Hallucination í•„í„°ë§: {text}")
                    return None

                # ìµœê·¼ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                self.recent_texts.append(text)
                if len(self.recent_texts) > 5:
                    self.recent_texts.pop(0)

                print(f"ğŸ“ í…ìŠ¤íŠ¸: {text}")

                return {
                    "text": text,
                    "language": info.language,
                    "device": self.device
                }

        except Exception as e:
            print(f"âŒ ì „ì‚¬ ì˜¤ë¥˜: {e}")
        finally:
            if os.path.exists(temp_file):
                os.remove(temp_file)

        return None

    def process_audio_stream(self, audio_data, callback=None):
        """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        self.processing_queue.put((audio_data, callback))

# WebSocket í•¸ë“¤ëŸ¬
@sock.route('/ws')
def websocket(ws):
    """WebSocket ì—°ê²° ì²˜ë¦¬"""
    print(f"ğŸ”Œ ìƒˆ WebSocket ì—°ê²°: {request.remote_addr}")

    audio_buffer = []
    chunk_size = 48000  # 3ì´ˆ ë¶„ëŸ‰ìœ¼ë¡œ ì¦ê°€ (ë” ê¸´ ì»¨í…ìŠ¤íŠ¸)

    def send_result(result):
        """ì²˜ë¦¬ ê²°ê³¼ ì „ì†¡"""
        if result:
            try:
                ws.send(json.dumps({
                    "type": "transcription",
                    **result
                }))
            except:
                pass

    try:
        while True:
            message = ws.receive()
            if message:
                data = json.loads(message)

                if data.get('type') == 'audio':
                    # Base64 ì˜¤ë””ì˜¤ ë°ì´í„° ë””ì½”ë”©
                    import base64
                    audio_bytes = base64.b64decode(data['data'])
                    audio_array = np.frombuffer(audio_bytes, dtype=np.float32)

                    # ë²„í¼ì— ì¶”ê°€
                    audio_buffer.extend(audio_array)

                    # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ëª¨ì´ë©´ ì²˜ë¦¬
                    if len(audio_buffer) >= chunk_size:
                        chunk = np.array(audio_buffer[:chunk_size])
                        audio_buffer = audio_buffer[chunk_size:]

                        # ë¹„ë™ê¸° ì²˜ë¦¬
                        stt_processor.process_audio_stream(chunk, send_result)

                elif data.get('type') == 'config':
                    # ì„¤ì • ì—…ë°ì´íŠ¸
                    ws.send(json.dumps({
                        "type": "config_updated",
                        "language": data.get('language', 'ko')
                    }))

    except Exception as e:
        print(f"WebSocket ì˜¤ë¥˜: {e}")
    finally:
        print(f"ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ: {request.remote_addr}")

# ë¼ìš°íŠ¸
@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index_keywords_scroll.html')

@app.route('/api/config')
def get_config():
    """ì„¤ì • ì •ë³´ ë°˜í™˜"""
    return jsonify({
        "gpu": torch.cuda.is_available(),
        "device": stt_processor.device if stt_processor else None,
        "llm_enabled": True,
        "buffer_mode": True  # ë²„í¼ ëª¨ë“œ í™œì„±í™” í‘œì‹œ
    })

# ë©”ì¸ ì‹¤í–‰
if __name__ == '__main__':
    # GPU ì„¤ì •
    if torch.cuda.is_available():
        torch.cuda.set_device(0)
        print(f"ğŸ–¥ï¸ GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

    # í‚¤ì›Œë“œ ì¶”ì¶œê¸° ì´ˆê¸°í™”
    keyword_extractor = KeywordExtractor()

    # STT í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    stt_processor = STTProcessor(keyword_extractor)
    if not stt_processor.load_model():
        print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ì„œë²„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)

    print("\n" + "="*60)
    print("ğŸ¤ STT + ğŸ¤– LLM í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œìŠ¤í…œ (ë²„í¼ë§ ëª¨ë“œ)")
    print("Real-time STT with Buffered AI Keyword Extraction")
    print("="*60)

    # ì„œë²„ ì‹œì‘
    print(f"\nğŸŒ í†µí•© ì„œë²„ ì‹œì‘: http://localhost:5000")
    print("ğŸ”‘ í‚¤ì›Œë“œ ì¶”ì¶œ í™œì„±í™” (ë²„í¼ë§: 5ì´ˆ/5ë¬¸ì¥)")
    print("WebSocketì€ /ws ê²½ë¡œì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n")

    app.run(host='0.0.0.0', port=5000, debug=False)